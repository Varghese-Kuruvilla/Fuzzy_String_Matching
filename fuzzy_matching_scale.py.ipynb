{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/varghese/miniconda3/envs/fuzzyname/lib/python3.7/site-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "from scipy.sparse import csr_matrix\n",
    "import sparse_dot_topn.sparse_dot_topn as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1040569 entries, 0 to 1040568\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   name    1040568 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 7.9+ MB\n",
      "None\n",
      "                         name\n",
      "0                 balteau ndt\n",
      "1   ex nihilo creations india\n",
      "2  watsontown alliance church\n",
      "3         uw zorgcompaan b.v.\n",
      "4          dynamic life coach\n"
     ]
    }
   ],
   "source": [
    "#Load dataset\n",
    "# filename = \"../Nanonets_Fuzzymatching/datasets/companynames_dataset.csv\"\n",
    "# df = pd.read_csv(filename, sep=';', usecols=['name'])\n",
    "# df.to_pickle(\"data.pickle\") \n",
    "\n",
    "df = pd.read_pickle(\"data.pickle\")\n",
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/varghese/miniconda3/envs/fuzzyname/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         name\n",
      "0                 balteau ndt\n",
      "1   ex nihilo creations india\n",
      "2  watsontown alliance church\n",
      "3              uw zorgcompaan\n",
      "4          dynamic life coach\n"
     ]
    }
   ],
   "source": [
    "#Data preprocessing\n",
    "#Convert to lowercase\n",
    "df[\"name\"] = df[\"name\"].str.lower()\n",
    "#Remove punctuation\n",
    "df[\"name\"] = df[\"name\"].str.replace('[^\\w\\s]','')\n",
    "#Remove stopwords\n",
    "stop = [\"agency\",\"gmbh\",\"pa\",\"and\" , \"group\",\"pc\",\"assn\",\\\n",
    "        \"hotel\",\"pharmacy\",\"assoc\",\"hotels\",\"plc\",\"associates\",\\\n",
    "        \"inc\",\"pllc\",\"association\",\"incorporated\",\"restaurant\",\\\n",
    "        \"bank\",\"international\",\"sa\",\"bv\",\"intl\",\"sales\",\\\n",
    "        \"co\",\"limited\",\"services\",\"comp\",\"company\",\"llc\",\"store\",\n",
    "        \"ltd\",\"travel\",\"dmd\",\"manufacturing\",\"enterprises\",\"mfg\"]\n",
    "df[\"name\"] = df[\"name\"]\\\n",
    "            .apply(lambda x: ' '.join([word for word in str(x).split() if word not in (stop)]))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 143395)\t0.6191461163997317\n",
      "  (0, 1009238)\t0.4830281286780922\n",
      "  (0, 143394)\t0.6191461163997317\n"
     ]
    }
   ],
   "source": [
    "#Compute Vectors\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "tf_idf_matrix = tfidf_vectorizer.fit_transform(df['name'].values.astype('U'))\n",
    "print(tf_idf_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def awesome_cossim_top(A, B, ntop, lower_bound=0):\n",
    "    # force A and B as a CSR matrix.\n",
    "    # If they have already been CSR, there is no overhead\n",
    "    A = A.tocsr()\n",
    "    B = B.tocsr()\n",
    "    M, _ = A.shape\n",
    "    _, N = B.shape\n",
    " \n",
    "    idx_dtype = np.int32\n",
    " \n",
    "    nnz_max = M*ntop\n",
    " \n",
    "    indptr = np.zeros(M+1, dtype=idx_dtype)\n",
    "    indices = np.zeros(nnz_max, dtype=idx_dtype)\n",
    "    data = np.zeros(nnz_max, dtype=A.dtype)\n",
    "\n",
    "    ct.sparse_dot_topn(\n",
    "        M, N, np.asarray(A.indptr, dtype=idx_dtype),\n",
    "        np.asarray(A.indices, dtype=idx_dtype),\n",
    "        A.data,\n",
    "        np.asarray(B.indptr, dtype=idx_dtype),\n",
    "        np.asarray(B.indices, dtype=idx_dtype),\n",
    "        B.data,\n",
    "        ntop,\n",
    "        lower_bound,\n",
    "        indptr, indices, data)\n",
    "\n",
    "    return csr_matrix((data,indices,indptr),shape=(M,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total computation time: 231.66275358200073\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "matches = awesome_cossim_top(tf_idf_matrix, tf_idf_matrix.transpose(), 10, 0.6)\n",
    "print(\"Total computation time:\",time.time()-start_time)\n",
    "\n",
    "#Save for later use\n",
    "# filehandler = open(\"matches.pkl\", 'wb') \n",
    "# pickle.dump(matches, filehandler)\n",
    "\n",
    "# filehandler = open(\"matches.pkl\",\"rb\")\n",
    "# matches = pickle.load(filehandler)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fuzzyname",
   "language": "python",
   "name": "fuzzyname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
